## Background 
Dilemma of Large-scale Suppevised 
### Problems 
1. No memory:Knowledge learned is not retained 
   - Knowledge is not cumulative 
   - Cannot learn by leveraging past learned knowledge  
2. Needs a large number of training example  
   - Human  can learn  effectively from a few example 
   - Human can learn to learn  

### What we want ? Learn as humans do. 
1. Humans have  the ability  to  recognize without seeing  example(zero-shot problem  )

2. Retain learned knowledge from  previous  task & usu  it to  help future learning(transfer learning ) 


## Few-Shot learning  
Few-shot  learning  aims to learn information about object categories from ***one,or only a few***,traning images.  

### Outlines of Few-shot learning   

####  1. Directly supervised   learning-based approach   

do not auxiliary data 
 directly learn one-shot classier   
- Instance -based learning  
- K-nearest neighbor  
- None-parameter methods 

#### 2. Transfer learning-based approaches:

Use knowledge from auxiliary data 
The  paradigm of <b> <font color=#dd0000>*learning  to  learn or  meta learning* </font></b>

- Attribute-based  algorithms  
- Meta-learning algorithms  
- Metric-larning  algorithms  
     - Matching Net  
     - Proto Net 
     - Relation Net  

#### 3. Data Augmentation for  One-shot Learning   

1.  Learning  one-shot models by utilizing the manifold information  of large amount  unlabelled data in semi-supervised  or transductive setting   

2. Adaptively learning  the one-shot classifier from off-shelf trained models 

3. Borrowing  example from relevant categories or semantic vocabularies to augment to  training  the  tranning set  

4. Synthesizing new labelled training by rending vital example or  composing  synthesized representations or  distort traning examples  

5. Generating new  examples using  Generative  Adversarial Networks(GANs) 

6. Attribute-guided augmentation(AGA) to synthesize sample at desired values or strength  


###  Meal80K Dataset 
   -  Includes 424 categories, a total of 81,734 images, with noise in real scenes 
   - Among them, 36 categories are less than 20, and 23 categories are less than 10 
   - In the real electronic receiving environment, the picture may have different light and dark environments, accompanied by other artificial noises such as bags and hands and feet.

#### Distribution relationship of Meal80K 
- Some classes(eg.chili ,melon,leafy vegetables et.al) are semantically or visually similar.
- Thus it is reasonable to assume that there are correlations between their classification weight vectors that could be exploited in order to reconstruct a more discriminative  classification weight vector for each of them

###  How to we reconstruct Few-shot problem on Meal80K datasets with noise?

#### Generating Classification Weight with GNN for K(zero/few)-Shot  Learning   based on Meal80K  

- Given an initial recognition model already trained on a set of base classes, the goal of this work is to develop a meta-model for few-shot learning 
- given as input some novel classes with few training examples per class(K=1,2,5,10,20...), must properly adapt the existing recognition model into a new model that can correctly classify in a unified way both the novel and the base classes  


#### Graph Neural Network based Denoising Autoencoder
- the DAE framework prescribes to apply Gaussian noise on some target weights and then train the DAE model r(.) to  reconstruct them. 
- take into account the inter-class relationships when reconstructing the classification weights of a set of classes(GNN) 



## Zero-Shot learning 
Zero-shot recognition uses textual or attribute-level descriptions of object classes to train classifiers. 
### ZSL  Problems 
1. Domain Shift  
   -  The same attribute, the visual characteristics may be different in different categories.
2. Semantic Gap  
   - The manifold (distribution structure) formed in the feature space is inconsistent with the manifold formed by the sample in the semantic space. 

#### It is very difficult to establish attribute description in the Meal80K datasets and thers exist a problem of domain drift. 
It is very suitable to establish a suitable mapping through AutoEncoder to get the semantic weight of each category(word embedding). 

#### Word Embeddings and Knowledge Graph  



### Schedule  

-  The classification model has produced 2.2T of data in real scenes, for a total of 18 million images 
   - Filtering ,Reconstruct  Meal Datasets   
   - Noise label(wrong label )

- Deployment 
    - Tornado (using non-blocking network I/O)  


### Thanks 