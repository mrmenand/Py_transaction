## 决策树 
分类决策树模型是表示基于特征对实例进行的分类的树形结构，决策树可以换成一个**if-then**规则的集合，也可以看做是定义在特征空间划分上的**类条件概率分布**。 

## 算法 
包括三部分：**特征选择、树的生成和树的剪枝**。常用的算法有ID3、C4.5和CART

决策树的生成对应于模型的**局部选择**（局部最优），剪枝则考虑**全局最优**。
### 特征选择 
决定用那个特征划分特征空间。 

#### 样本集合D对特征A的信息增益（ID3） 
$$ 
g(D,A)=H(D)-H(D|A) \\
H（D） = -\sum_{k=1}^K\frac{|C_k|}{|D|}\log_2\frac{|C_k|}{|D|} \\ 
H(D|A)=\sum_{i=1}^n\frac{|D_i|}{|D|}H(D_i)=-\sum_{i=1}^n\frac{|D_i|}{|D|}\sum_{k=1}^K\frac{|D_{ik}|}{|D_i|}\log_2\frac{|D_{ik}|}{|D_i|}$$
其中$H(D)$是数据集的熵，$H(D_i)$是数据$D_i$的熵$H(D|A)$是数据集$D$对特征$A$的条件熵。$D_i$是$D$中特征$A$取第$i$值的样本子集，$C_k$是D中属于第$k$类的样本子集。$n$是特征$A$取值的个数，$K$是类的个数。

#### 样本几个D对于特征A的信息增益比（C4.5）
